{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"workingEndToEndeNoEdit3.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1ccu1V_vEvRzDAN19HxuJ4b2kyvYpFpnK","authorship_tag":"ABX9TyOefCoIUZ4FywZaIC7CUZpY"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"dO3GtTgLVFAl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597157864448,"user_tz":360,"elapsed":1005,"user":{"displayName":"Matthew Daw","photoUrl":"","userId":"04663724258237896856"}},"outputId":"84def1a5-05f1-4c3b-ba4e-55bb6f4d37f6"},"source":["cd drive/"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xG_Em07ZVOR_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597157864785,"user_tz":360,"elapsed":1289,"user":{"displayName":"Matthew Daw","photoUrl":"","userId":"04663724258237896856"}},"outputId":"058ea68f-9f0b-4d1a-d9ef-82e8fc0f28fe"},"source":["cd My\\ Drive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zUGZKRvJVPDu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597157864788,"user_tz":360,"elapsed":1251,"user":{"displayName":"Matthew Daw","photoUrl":"","userId":"04663724258237896856"}},"outputId":"88919d7d-1e0d-4b5d-9898-be5858c7f82b"},"source":["cd Plate_detect_and_recognize-master/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Plate_detect_and_recognize-master\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-EDrObcrVSEB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597157868822,"user_tz":360,"elapsed":5270,"user":{"displayName":"Matthew Daw","photoUrl":"","userId":"04663724258237896856"}}},"source":["# remove warning message\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","\n","\n","# required library\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","from utils import detect_lp\n","from os.path import splitext,basename\n","from keras.models import model_from_json\n","from keras.preprocessing.image import load_img, img_to_array\n","from keras.applications.mobilenet_v2 import preprocess_input\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.linear_model import LinearRegression\n","import glob\n","import math\n","import statistics\n","from operator import itemgetter"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"SaJii7oUVWla","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597157868829,"user_tz":360,"elapsed":5263,"user":{"displayName":"Matthew Daw","photoUrl":"","userId":"04663724258237896856"}}},"source":["def load_model(path):\n","    try:\n","        path = splitext(path)[0]\n","        with open('%s.json' % path, 'r') as json_file:\n","            model_json = json_file.read()\n","        model = model_from_json(model_json, custom_objects={})\n","        model.load_weights('%s.h5' % path)\n","        print(\"Loading model successfully...\")\n","        return model\n","    except Exception as e:\n","        print(e)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"aS8h8ebsVXxb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597157899369,"user_tz":360,"elapsed":35768,"user":{"displayName":"Matthew Daw","photoUrl":"","userId":"04663724258237896856"}},"outputId":"cc7b94de-900f-4108-9e03-c6e005054c0d"},"source":["wpod_net_path = \"wpod-net.json\"\n","wpod_net = load_model(wpod_net_path)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Loading model successfully...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iOVRw3sYVZjk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597157899378,"user_tz":360,"elapsed":35760,"user":{"displayName":"Matthew Daw","photoUrl":"","userId":"04663724258237896856"}}},"source":["def preprocess_image(image_path,resize=False):\n","    img = cv2.imread(image_path)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img = img / 255\n","    if resize:\n","        img = cv2.resize(img, (224,224))\n","    return img\n","\n","def get_plate(image_path):\n","    Dmax = 608\n","    Dmin = 288\n","    vehicle = preprocess_image(image_path)\n","    ratio = float(max(vehicle.shape[:2])) / min(vehicle.shape[:2])\n","    side = int(ratio * Dmin)\n","    bound_dim = min(side, Dmax)\n","    _ , LpImg, _, cor = detect_lp(wpod_net, vehicle, bound_dim, lp_threshold=0.5)\n","    return vehicle, LpImg, cor"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"8E0Gmd1gVeRH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"error","timestamp":1597157899652,"user_tz":360,"elapsed":36021,"user":{"displayName":"Matthew Daw","photoUrl":"","userId":"04663724258237896856"}},"outputId":"5b60f083-742e-47fb-c2a1-2f3ff93afa7e"},"source":["def basic_method(plate_image):\n","    gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)\n","    blur = cv2.GaussianBlur(gray,(7,7),0)\n","    \n","    binary = cv2.threshold(blur, 180, 255,\n","                         cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","    \n","    kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n","    thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel3)\n","    return [plate_image, gray, blur, binary, thre_mor]\n","\n","def color_method(colorNumber, plate_image):\n","  possibleImages = []\n","  b = plate_image.copy()\n","  b = b[:, :, colorNumber]\n","  y = math.floor(b.shape[0]/2.4)\n","  x = math.floor(b.shape[1]/9)\n","  crop_img = b[y:int(y*2), x:int(x*8.3)]\n","  flatArray = b.flatten()\n","  cangeV =  np.percentile(flatArray, [32])\n","  image = cv2.cvtColor(b, cv2.COLOR_BGR2RGB)\n","  gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n","  _, binary = cv2.threshold(gray, cangeV, cangeV, cv2.THRESH_BINARY_INV)\n","\n","\n","  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","  \n","  blur = cv2.GaussianBlur(gray,(7,7),0)\n","  \n","  binary = cv2.threshold(blur, 180, 255,\n","                        cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n","  \n","  kernel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n","  thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel3)\n","  return [plate_image, gray, blur, binary, thre_mor]\n","\n","def visualize_set(plot_image):\n","  # visualize results    \n","  fig = plt.figure(figsize=(12,7))\n","  plt.rcParams.update({\"font.size\":18})\n","  grid = gridspec.GridSpec(ncols=2,nrows=3,figure = fig)\n","  # plot_name = [\"plate_image\",\"gray\",\"blur\",\"binary\",\"dilation\"]\n","\n","  for i in range(len(plot_image)):\n","      fig.add_subplot(grid[i])\n","      plt.axis(False)\n","      # plt.title(plot_name[i])\n","      plt.imshow(plot_image[i])\n","\n","def getFilteredPlateImages(path):\n","  returnArray = []\n","  test_image_path = path\n","  vehicle, LpImg,cor = get_plate(test_image_path)\n","\n","  if (len(LpImg)): #check if there is at least one license image\n","    # Scales, calculates absolute values, and converts the result to 8-bit.    \n","    plate_image = cv2.convertScaleAbs(LpImg[0], alpha=(255.0))\n","    returnArray.append(basic_method(plate_image))\n","    for i in range(3):\n","      returnArray.append(color_method(i,plate_image))\n","      \n","  return returnArray\n","\n","# filteredPlateImages =  getFilteredPlateImages(\"Plate_examples/50States.jpg\")\n","# filteredPlateImages =  getFilteredPlateImages(\"Plate_examples/germany_car_plate.jpg\")\n","filteredPlateImages =  getFilteredPlateImages(\"Plate_examples/photo2.JPG\")"],"execution_count":8,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-eb6e3f859e07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# filteredPlateImages =  getFilteredPlateImages(\"Plate_examples/50States.jpg\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# filteredPlateImages =  getFilteredPlateImages(\"Plate_examples/germany_car_plate.jpg\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mfilteredPlateImages\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgetFilteredPlateImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UtahPlates/1.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-eb6e3f859e07>\u001b[0m in \u001b[0;36mgetFilteredPlateImages\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0mreturnArray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0mtest_image_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m   \u001b[0mvehicle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLpImg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_plate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLpImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#check if there is at least one license image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-5d41d7ed5b42>\u001b[0m in \u001b[0;36mget_plate\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mDmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m608\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mDmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m288\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mvehicle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvehicle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvehicle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mside\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mDmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-5d41d7ed5b42>\u001b[0m in \u001b[0;36mpreprocess_image\u001b[0;34m(image_path, resize)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}]},{"cell_type":"code","metadata":{"id":"WnfAr8iMB1G9","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pEDATao4Yhpl","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597157899644,"user_tz":360,"elapsed":35990,"user":{"displayName":"Matthew Daw","photoUrl":"","userId":"04663724258237896856"}}},"source":["def sort_contours(cnts,reverse = False):\n","    i = 0\n","    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n","    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n","                                        key=lambda b: b[1][i], reverse=reverse))\n","    return cnts\n","\n","def cutOutliers(inArray):\n","  returnArray = []\n","  reducedArray = [((sec[0]+sec[1])/2+(sec[2]+sec[3])/2)/2 for sec in inArray]\n","  mean = statistics.mean(reducedArray)\n","  stdevi = statistics.stdev(reducedArray)\n","  for i in range(len(inArray)):\n","    if mean-stdevi < reducedArray[i] < mean+stdevi:\n","      returnArray.append(inArray[i])\n","  return returnArray\n","\n","def cutOutliersArea(inArray):\n","  returnArray = []\n","  reducedArray = [((con[1] - con[0]) * (con[3] - con[2])) for con in inArray]\n","  mean = statistics.mean(reducedArray)\n","  stdevi = statistics.stdev(reducedArray)\n","  for i in range(len(inArray)):\n","    if mean-(stdevi*1.5) < reducedArray[i] < mean+(stdevi*1.5):\n","      returnArray.append(inArray[i])\n","  return returnArray\n","\n","def fineChopLetters(contours):\n","\n","  contours = cutOutliersArea(contours)\n","  heightList = []\n","  go = True\n","  rScore = .05\n","  passing = 0\n","  while(rScore < .9 and passing < 6):\n","    heightList = []\n","    heightList = [con[1] - con[0] for con in contours]\n","    average = np.mean(heightList)\n","    # if abs(rScore) < .85:\n","    heightDifList = [abs(cow - average) for cow in heightList]\n","    indexToRemove = np.argmax(heightDifList)\n","    xPointOfInterest = np.array([(contours[indexToRemove][2] + contours[indexToRemove][3]) / 2])\n","    xPointOfInterest = xPointOfInterest.reshape(1,-1)\n","    tempContorCopy = contours.copy()\n","    del tempContorCopy[indexToRemove]\n","    bottomEdge = [((con[2] + con[3])/2, con[0]) for con in tempContorCopy ]\n","    topEdge = [((con[2] + con[3])/2, con[1]) for con in tempContorCopy ]\n","\n","    X = [((con[2] + con[3])/2) for con in tempContorCopy ]\n","    X = np.array(X).reshape((-1, 1))\n","\n","    model = LinearRegression()\n","\n","    bottomEdgeY = np.array([con[0] for con in tempContorCopy ])\n","    model.fit(X, bottomEdgeY)\n","    newYValue = model.predict(xPointOfInterest)\n","    contours[indexToRemove][0] = int(newYValue)\n","    rSq1 = model.score(X, bottomEdgeY)\n","\n","    topEdgeY = np.array([con[1] for con in tempContorCopy ])\n","    model.fit(X, topEdgeY)\n","    newYValue = model.predict(xPointOfInterest)\n","    contours[indexToRemove][1] = int(newYValue)\n","    rSq2 = model.score(X, topEdgeY)\n","    rScore = (rSq1 + rSq2) / 2\n","    passing += 1\n","    \n","  return contours\n","\n","def splitContour(con):\n","  midPoint = int((con[3] + con[2])/2)\n","  con1 = con.copy()\n","  con1[2] = midPoint\n","  con2 = con.copy()\n","  con2[3] = midPoint\n","  return [con1,con2]\n","\n","def getNeighbors(one,two):\n","\n","  if one[1] - one[0] > 10 and two[1] - two[0] > 10:\n","    if (one[1] - one[0]) - (two[1] - two[0]) < 10:\n","      if abs(one[0] - two[0]) < 5 or abs(one[1] - two[1]) < 5:\n","        if abs(one[2]-two[3]) < 3 or abs(one[3]-two[2]) < 3:\n","          return [max(one[0],two[0]), min(one[1],two[1]), min(one[2],two[2]), max(one[3],two[3])]\n","  return None\n","\n","def fineChopSmallLetters(contours):\n","  returnContours = []\n","  finalReturnContours = []\n","  if len(contours) == 6:\n","\n","    processingContours = contours.copy()\n","\n","    potentialCombine = []\n","\n","    while (processingContours):\n","      tempContour = processingContours.pop()\n","      width = tempContour[3] - tempContour[2]\n","      height = tempContour[1] - tempContour[0]\n","      if width/height > 1:\n","        processingContours = processingContours + splitContour(tempContour)\n","      elif height/width > 1.7:\n","        potentialCombine.append(tempContour)\n","      else:\n","        returnContours.append(tempContour)\n","  \n","    if len(potentialCombine) > 1:\n","\n","      left = [div[2] for div in potentialCombine]\n","      right = [div[3] for div in potentialCombine]\n","      \n","      for i in range(len(left)-1):\n","        go = True\n","        for two in potentialCombine[i+1:]:\n","          temp = getNeighbors(potentialCombine[i],two)\n","          if temp != None:\n","            returnContours.append(temp)\n","            go = False\n","        if go:\n","          returnContours.append(potentialCombine[i])\n","    elif len(potentialCombine) == 1:\n","      returnContours.append(potentialCombine[0])\n","  if len(returnContours) > 2:\n","    returnContours = cutOutliers(returnContours)\n","    returnContours = sorted(returnContours, key=itemgetter(2))\n","  return returnContours\n","\n","\n","def getContorSets(filteredImages):\n","\n","  contour_sets = []\n","\n","  for imageSet in filteredImages:\n","    \n","    plate_image = imageSet[0]\n","\n","    binary = imageSet[3]\n","    thre_mor = imageSet[4]\n","\n","    cont, _  = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","    # creat a copy version \"test_roi\" of plat_image to draw bounding box\n","    test_roi_small_l = plate_image.copy()\n","    test_roi = plate_image.copy()\n","\n","    # Initialize a list which will be used to append charater image\n","    crop_characters = []\n","    small_letters = []\n","\n","    # define standard width and height of character\n","    digit_w, digit_h = 30, 60\n","\n","    totalArea = plate_image.shape[0] * plate_image.shape[1]\n","    # print(plate_image)\n","\n","\n","    small_letters_list_top = []\n","    small_letters_list_bottom = []\n","    \n","    for c in sort_contours(cont):\n","        (x, y, w, h) = cv2.boundingRect(c)\n","        ratio = h/w\n","        contorArea = x*h\n","        if (x + w) < plate_image.shape[1] * .95: #only select if width is relatively small\n","          if y + h < plate_image.shape[0] *.45: #only select contor not in middle\n","            small_letters_list_top.append([y,y+h,x,x+w])\n","          if y > plate_image.shape[0] *.55:\n","            small_letters_list_bottom.append([y,y+h,x,x+w])\n","\n","    if(len(small_letters_list_top) > 1):\n","      small_letters_list_top = fineChopSmallLetters(small_letters_list_top)\n","      for curr in small_letters_list_top:\n","        cv2.rectangle(test_roi_small_l, (curr[2], curr[0]), (curr[3], curr[1]), (0, 255,0), 2)\n","        curr_num = thre_mor[curr[0]:curr[1],curr[2]:curr[3]]\n","        curr_num = cv2.resize(curr_num, dsize=(digit_w, digit_h))\n","        _, curr_num = cv2.threshold(curr_num, 220, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","        small_letters.append(curr_num)\n","    count = 0\n","    curr_num_list = []\n","    for c in sort_contours(cont):\n","        # cout = count + 1\n","        # if count == 2\n","        (x, y, w, h) = cv2.boundingRect(c)\n","        ratio = h/w\n","        if .9<=ratio<=4: # Only select contour with defined ratio\n","          if y < plate_image.shape[0] *.6 and y + h > plate_image.shape[0] *.4: \n","            curr_num_list.append([y,y+h,x,x+w])\n","\n","    if(len(curr_num_list) > 1):\n","      curr_num_list = fineChopLetters(curr_num_list)\n","      for curr in curr_num_list:\n","        cv2.rectangle(test_roi, (curr[2], curr[0]), (curr[3], curr[1]), (0, 255,0), 2)\n","        curr_num = thre_mor[curr[0]:curr[1],curr[2]:curr[3]]\n","        curr_num = cv2.resize(curr_num, dsize=(digit_w, digit_h))\n","        _, curr_num = cv2.threshold(curr_num, 220, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","        crop_characters.append(curr_num)\n","      print(\"Detect {} letters...\".format(len(crop_characters)))\n","      fig = plt.figure(figsize=(10,6))\n","      plt.axis(False)\n","      # plt.imshow(test_roi)\n","      plt.imshow(test_roi_small_l)\n","      # return curr_num_list\n","      contour_sets.append(small_letters)\n","      contour_sets.append(crop_characters)\n","  return contour_sets\n","\n","crop_characters_set = getContorSets(filteredPlateImages)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1jiPF5Ooz6g1","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597157899646,"user_tz":360,"elapsed":35975,"user":{"displayName":"Matthew Daw","photoUrl":"","userId":"04663724258237896856"}}},"source":["json_file = open('MobileNets_character_recognition.json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","model = model_from_json(loaded_model_json)\n","model.load_weights(\"License_character_recognition_weight.h5\")\n","\n","labels = LabelEncoder()\n","labels.classes_ = np.load('license_character_classes.npy')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AliYNAnv4Ffx","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597157899647,"user_tz":360,"elapsed":35944,"user":{"displayName":"Matthew Daw","photoUrl":"","userId":"04663724258237896856"}}},"source":["def predict_from_model(image,model,labels):\n","    plt.imshow(image)\n","    # return\n","    image = cv2.resize(image,(80,80))\n","    image = np.stack((image,)*3, axis=-1)\n","    prediction = labels.inverse_transform([np.argmax(model.predict(image[np.newaxis,:]))])\n","    return prediction\n","\n","def read_letters(crop_characters_set):\n","  for chop_characters2 in crop_characters_set:\n","    fig = plt.figure(figsize=(15,3))\n","    cols = len(chop_characters2)\n","    grid = gridspec.GridSpec(ncols=cols,nrows=1,figure=fig)\n","\n","    final_string = ''\n","    for i,character in enumerate(chop_characters2):\n","        fig.add_subplot(grid[i])\n","        title = np.array2string(predict_from_model(character,model,labels))\n","        plt.title('{}'.format(title.strip(\"'[]\"),fontsize=20))\n","        final_string+=title.strip(\"'[]\")\n","        plt.axis(False)\n","        plt.imshow(character,cmap='gray')\n","\n","    print(final_string)\n","read_letters(crop_characters_set)"],"execution_count":null,"outputs":[]}]}